{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dandi Archive metadata for Qdrant vector embeddings\n",
    "\n",
    "- Customize the Dandiset blacklist as needed\n",
    "- Run the script to filter and process Dandiset metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version (0.58.0) of dandi/dandi-cli is available. You are using 0.56.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: Number of items: 178\n",
      "REMOVED -- 000027: Test dataset for testing dandi-cli.\n",
      "REMOVED -- 000029: Test dataset for development purposes\n",
      "REMOVED -- 000126: NWB API Test Data\n",
      "REMOVED -- 000299: Stephen Test Set\n",
      "REMOVED -- 000411: test\n",
      "REMOVED -- 000470: Test\n",
      "REMOVED -- 000529: Test 2\n",
      "REMOVED -- 000544: Test Dataset\n",
      "REMOVED -- 000545: Test set\n",
      "NOTE: 1 blacklisted dandiset(s) not removed.\n",
      "END: Number of items: 169\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "\n",
    "dandiset_blacklist = [\n",
    "    \"000545\",\n",
    "    \"000470\",\n",
    "    \"000411\",\n",
    "    \"000529\",\n",
    "    \"000299\",\n",
    "    \"000029\",\n",
    "    \"000027\",\n",
    "    \"000126\",\n",
    "    \"000544\",\n",
    "    \"000068\",\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_path = os.path.abspath('.')\n",
    "sys.path.append(os.path.join(notebook_path, '..'))\n",
    "\n",
    "from rest.clients.dandi import DandiClient\n",
    "from rest.clients.openai import OpenaiClient\n",
    "from rest.clients.llama2 import Llama2Client\n",
    "from rest.clients.qdrant import QdrantClient\n",
    "from rest.constants import OPENAI_COLLECTION_NAME, LLAMA2_COLLECTION_NAME\n",
    "\n",
    "dandi_client = DandiClient()\n",
    "openai_client = OpenaiClient()\n",
    "# llama_client = Llama2Client()\n",
    "qdrant_client = QdrantClient(host=\"https://906c3b3f-d3ff-4497-905f-2d7089487cf9.us-east4-0.gcp.cloud.qdrant.io\")\n",
    "\n",
    "all_metadata = dandi_client.get_all_dandisets_metadata()\n",
    "all_metadata_formatted: list[dict] = dandi_client.collect_relevant_metadata(metadata_list=all_metadata)\n",
    "print(\"START: Number of items:\", len(all_metadata_formatted))\n",
    "\n",
    "filtered_all_metadata_formatted = []\n",
    "for i, dandiset in enumerate(all_metadata_formatted):\n",
    "    if not any(item in str(dandiset[\"dandiset_id\"]).split(\":\")[-1] for item in dandiset_blacklist):\n",
    "        filtered_all_metadata_formatted.append(dandiset)\n",
    "    else:\n",
    "        print(f\"REMOVED -- {dandiset['dandiset_id']}: {dandiset['title']}\")\n",
    "\n",
    "num_not_removed = len(dandiset_blacklist) - (len(all_metadata_formatted) - len(filtered_all_metadata_formatted))\n",
    "if num_not_removed:\n",
    "    print(f\"NOTE: {num_not_removed} blacklisted dandiset(s) not removed.\")\n",
    "\n",
    "print(\"END: Number of items:\", len(filtered_all_metadata_formatted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwrite current Qdrant points in `data/qdrant_points.json`\n",
    "\n",
    "- Make sure to run the previous script to filter Dandiset metadata before running this script\n",
    "- Choose a valid embedding model for which the qdrant points should be generated/updated (or leave model field empty to update all model qdrant points)\n",
    "- Run the script to retrieve embeddings and save them to `data/qdrant_points.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All points added to collection dandi_collection_ada002\n",
      "Number of emb items: 169\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "\n",
    "# choose one of: \"ada002\" or \"llama2\" or leave empty to update all model qdrant points\n",
    "model = \"ada002\"\n",
    "\n",
    "# -----------------------------\n",
    "\n",
    "def get_embeddings(client, metadata):\n",
    "    return client.get_embeddings(\n",
    "        metadata_list=metadata,\n",
    "        save_to_file=True\n",
    "    )\n",
    "\n",
    "if model == \"ada002\":\n",
    "    emb = get_embeddings(openai_client, filtered_all_metadata_formatted)\n",
    "    qdrant_client.create_collection(collection_name=OPENAI_COLLECTION_NAME)\n",
    "    qdrant_client.add_points_to_collection(collection_name=OPENAI_COLLECTION_NAME, embeddings_objects=emb)\n",
    "    print(\"Number of emb items:\", len(emb))\n",
    "# elif model == \"llama2\":\n",
    "#     emb = get_embeddings(llama_client, filtered_all_metadata_formatted)\n",
    "#     qdrant_client.create_collection(collection_name=LLAMA2_COLLECTION_NAME)\n",
    "#     qdrant_client.add_points_to_collection(collection_name=LLAMA2_COLLECTION_NAME, embeddings_objects=emb)\n",
    "#     print(\"Number of emb items:\", len(emb))\n",
    "elif not model:\n",
    "    emb1 = get_embeddings(openai_client, filtered_all_metadata_formatted)\n",
    "    # emb2 = get_embeddings(llama_client, filtered_all_metadata_formatted)\n",
    "    print(\"Number of openai emb items:\", len(emb1))\n",
    "    # print(\"Number of llama2 emb items:\", len(emb2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dandivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
